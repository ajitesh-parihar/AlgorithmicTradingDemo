{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca4a000c",
   "metadata": {},
   "outputs": [],
   "source": [
    "globals().clear\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a83aa3d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow       as tf\n",
    "import keras.optimizers as op\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow                     import keras\n",
    "from tensorflow.keras.models        import Sequential\n",
    "from tensorflow.keras.layers        import Dense\n",
    "from tensorflow.keras.layers        import Dropout\n",
    "from tensorflow.keras.optimizers    import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30a5aea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "df = pd.read_csv('../../df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c07eb449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of tickers for stocks in our data set. Sort the ticker list since our df will be alphabetically arranged.\n",
    "tickers = [\"AAPL\", 'XOM', 'IBM', 'KO', 'CVX', 'BA', 'PFE', 'MSFT', 'T', 'WMT',\n",
    "       'F', 'NFLX', 'JPM', 'MCD', 'GE', 'NVDA', 'JNJ', 'BAC', 'C', 'AMZN',\n",
    "       'INTC', 'CSCO', 'TSLA', 'GOOGL', 'AMD', 'BABA', 'VZ', 'DIS',\n",
    "       'META']\n",
    "tickers.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918b8d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this specific trial drop PLTR since data is not complete\n",
    "df = df[df.stock_ID != \"PLTR\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e20451bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['DATETIME']= pd.to_datetime(df['DATETIME'], format='%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "528d0aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by time so that the first 29 rows occupy the first time value for all the stocks. \n",
    "# Fill in 0's for missing values for now.\n",
    "df = df.set_index('DATETIME')\n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30be49c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the length of the df ; For this file we need 7 months\n",
    "# We use the first 3 months to make the first prediction, then shift window\n",
    "# Then we will repeat this for the next 4 months (Hence total is 7 months needed)\n",
    "df = df.sort_index().loc['2022-06-01':'2022-12-30']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3eb92e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set the DATETIME for fecha \n",
    "DATETIME = df.index.values[::29]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66568df5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort dataframe such that it is both in sequential order, and also in alphabetical order for each day \n",
    "#(i.e first entry for each time entry should be AAPL, and last should be XOM).\n",
    "df.sort_values([\"DATETIME\", \"stock_ID\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e05e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select individual stocks and remove demographics\n",
    "aapl = df.iloc[::29  ,:74]\n",
    "f    = df.iloc[10::29,:74]\n",
    "nvda = df.iloc[22::29,:74]\n",
    "tsla = df.iloc[25::29,:74]\n",
    "wmt  = df.iloc[27::29,:74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "416c0342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 23338.8594\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 23068.5410\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 22660.7793\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 22017.8301\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 20995.3672\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 19480.9238\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 17376.0371\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 14635.6865\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 11414.7041\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8004.5645\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4796.7847\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2349.6423\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 944.7346\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 449.2375\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 304.3290\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 285.9841\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 284.5130\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 267.4019\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 244.1954\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 248.9679\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 244.2811\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 240.0652\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 222.1794\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 212.8133\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 207.1307\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 199.4754\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 198.5521\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 197.3068\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 179.9203\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 186.1036\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 186.1817\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 175.0623\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 179.3841\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 175.1874\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 175.9176\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 177.5024\n",
      "Epoch 36: early stopping\n",
      "Count Down: 16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 192.0582\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 191.0830\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 168.3494\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 171.5945\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 163.5876\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 166.7273\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 168.9213\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 171.1054\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 159.4266\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 170.7978\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 161.6021\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 158.6537\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 161.6132\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 172.0340\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 161.9683\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 159.9404\n",
      "Epoch 16: early stopping\n",
      "Count Down: 15\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 166.3963\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 158.1470\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 172.6947\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 177.3019\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 163.4352\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 165.6803\n",
      "Epoch 6: early stopping\n",
      "Count Down: 14\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 189.8558\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 162.2758\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 174.8083\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 166.3483\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 167.0606\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 162.7626\n",
      "Epoch 6: early stopping\n",
      "Count Down: 13\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 175.1855\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 166.1444\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 144.9447\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 168.4939\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 158.4544\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 154.5413\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 154.2593\n",
      "Epoch 7: early stopping\n",
      "Count Down: 12\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 163.0576\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 164.2288\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.4606\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 164.0565\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 160.1107\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 157.8170\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.1144\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 164.5541\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 161.8977\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 170.5251\n",
      "Epoch 10: early stopping\n",
      "Count Down: 11\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 172.8969\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 147.2771\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.8244\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 164.5229\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 160.6073\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 148.6406\n",
      "Epoch 6: early stopping\n",
      "Count Down: 10\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 151.9899\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.4559\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 172.3120\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 169.5930\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 149.2177\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 162.0267\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 170.2285\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 159.5450\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 163.0435\n",
      "Epoch 9: early stopping\n",
      "Count Down: 9\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 161.9243\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.7741\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 163.0632\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.9977\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 154.5445\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 165.4491\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 162.4809\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 166.4554\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 154.9357\n",
      "Epoch 9: early stopping\n",
      "Count Down: 8\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 183.0150\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 168.7333\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.5191\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 154.2272\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 152.2167\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 159.1375\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 157.0442\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 152.0464\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 145.9657\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 153.4856\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 159.7821\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 161.9454\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 154.2074\n",
      "Epoch 13: early stopping\n",
      "Count Down: 7\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 156.3984\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 145.5318\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.4857\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 150.4834\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 148.6601\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.3586\n",
      "Epoch 6: early stopping\n",
      "Count Down: 6\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 149.3205\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 147.9165\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.0289\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 139.6194\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.6774\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 149.0319\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 144.3241\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 159.1127\n",
      "Epoch 8: early stopping\n",
      "Count Down: 5\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 143.5872\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 152.3295\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 143.8789\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 143.3129\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.8283\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 148.0368\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 150.1940\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 150.4196\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 141.4674\n",
      "Epoch 9: early stopping\n",
      "Count Down: 4\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 179.7265\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 148.5354\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 143.1854\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.9832\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 139.9779\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 142.2447\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 137.3600\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 143.3700\n",
      "Epoch 8: early stopping\n",
      "Count Down: 3\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 146.7197\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 143.3147\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 144.0028\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 136.1099\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 145.7324\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 146.6036\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 138.3642\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 143.0419\n",
      "Epoch 8: early stopping\n",
      "Count Down: 2\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 140.9019\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 136.9435\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 136.3156\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 142.2415\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 137.1627\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 140.9555\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 139.8594\n",
      "Epoch 7: early stopping\n",
      "Count Down: 1\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 149.8776\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.9919\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 141.1315\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 138.6006\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 131.9583\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 137.6578\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 135.6413\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 140.3765\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 136.6414\n",
      "Epoch 9: early stopping\n",
      "Count Down: 0\n"
     ]
    }
   ],
   "source": [
    "num_companies = 1  # 29 companies in our dataset.\n",
    "days = 5\n",
    "step_rows  = 24 * num_companies * 5  # 24 time periods per day per stock\n",
    "total_rows = len(aapl['2022-06-01':'2022-12-30'])  # Define total length to predict on\n",
    "train_rows = len(aapl['2022-06-01':'2022-08-31'])  # Define length of training window\n",
    "\n",
    "\n",
    "scale_X = MinMaxScaler()\n",
    "model_1 = Sequential()\n",
    "model_1.add(Dense(100, activation = 'relu', input_dim = aapl.iloc[:,1:-1].shape[1]))  # initiating with 100 neurons\n",
    "model_1.add(Dense(100, activation = 'relu', input_dim = aapl.iloc[:,1:-1].shape[1]))\n",
    "model_1.add(Dropout(0.25))                                                          # adding dropout to avoid overfitting\n",
    "model_1.add(Dense(1))                                                               # output layer\n",
    "\n",
    "opt = Adam(amsgrad = True, lr = 0.001, beta_1 = 0.79, beta_2 = 0.999)             # using Adam optimizer, at a learning rate of 0.001\n",
    "model_1.compile(loss = 'mse', optimizer = opt)                                      # compiling model\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "aapl_result = pd.DataFrame(columns=['DATETIME', 'ACTUAL', 'PREDICTED', 'DIFFERENCE', 'TRAIN_DURATION'])\n",
    "\n",
    "for i in range(0, total_rows - train_rows, step_rows):\n",
    "    st = time.time()\n",
    "    # 1. Obtain X and y\n",
    "    train  = aapl.iloc[i:train_rows + i, 1:] \n",
    "    test   = aapl.iloc[train_rows + i:train_rows + i + step_rows, 1:]  \n",
    "    X_train, y_train = train.iloc[:, 1:], train.iloc[:, 0]\n",
    "    X_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]\n",
    "\n",
    "\n",
    "    \n",
    "    # 2. Scale X\n",
    "    X_train = scale_X.fit_transform(X_train)\n",
    "    X_test = scale_X.transform(X_test)\n",
    "\n",
    "    # 3. Fit and Predict\n",
    "    model_1.fit(X_train, y_train, epochs=200, batch_size=256, callbacks=[es])\n",
    "    y_hat = model_1.predict(X_test, verbose=False)\n",
    "    et = time.time()\n",
    "\n",
    "    # 4. Save data with prediction\n",
    "    fecha = DATETIME[train_rows + i:train_rows + i + step_rows]\n",
    "    datos = {\n",
    "        'DATETIME': fecha.ravel(),\n",
    "        'ACTUAL': y_test.ravel(),\n",
    "        'PREDICTED': y_hat.ravel(),\n",
    "        'DIFFERENCE': abs(y_hat.ravel() - y_test.ravel()),\n",
    "        'TRAIN_DURATION': np.full(y_hat.ravel().shape[0], et - st)\n",
    "    }\n",
    "    data = pd.DataFrame(data=datos)\n",
    "    aapl_result = pd.concat([aapl_result, data], ignore_index=True)\n",
    "\n",
    "    print(\"Count Down:\", int((total_rows - train_rows - i) / step_rows))\n",
    "    # print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4442c511",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 179.5450\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 158.8222\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.4080\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 99.5601\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 57.7351\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 20.1386\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.9147\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3.1890\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.8149\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2.2267\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2.2139\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2.0280\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2.0718\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 2.0241\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.8592\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.8395\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7658\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7833\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.7990\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7172\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7200\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6511\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5483\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6607\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6801\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6673\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5468\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5838\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5054\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5497\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5856\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4351\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5276\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6113\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5099\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.5405\n",
      "Epoch 36: early stopping\n",
      "Count Down: 16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.8219\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.7642\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.5823\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.5492\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.5902\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6068\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6430\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6134\n",
      "Epoch 8: early stopping\n",
      "Count Down: 15\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6880\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5301\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5351\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6233\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5513\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5012\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5264\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5035\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4128\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5076\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6204\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5291\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4512\n",
      "Epoch 13: early stopping\n",
      "Count Down: 14\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6486\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6104\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4829\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4859\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5469\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5629\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4937\n",
      "Epoch 7: early stopping\n",
      "Count Down: 13\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.9499\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5582\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6667\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.6538\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5326\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5381\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6457\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5401\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.5137\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6014\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5448\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4397\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4902\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4573\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4124\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4934\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4833\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5483\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5230\n",
      "Epoch 19: early stopping\n",
      "Count Down: 12\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.6067\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4213\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5311\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5008\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3333\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4479\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5557\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4110\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4718\n",
      "Epoch 9: early stopping\n",
      "Count Down: 11\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4828\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4793\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4471\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4812\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.4815\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5519\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5642\n",
      "Epoch 7: early stopping\n",
      "Count Down: 10\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.4516\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5624\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.4553\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5115\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4482\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4683\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4538\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4497\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5027\n",
      "Epoch 9: early stopping\n",
      "Count Down: 9\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4703\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4927\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4577\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5167\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4680\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4794\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4420\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4246\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4225\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4077\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4457\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3949\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4450\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4092\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4398\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4242\n",
      "Epoch 16: early stopping\n",
      "Count Down: 8\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4552\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4206\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4239\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.5108\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2736\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3120\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3348\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4296\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4600\n",
      "Epoch 9: early stopping\n",
      "Count Down: 7\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2975\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4044\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4625\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3771\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3317\n",
      "Epoch 5: early stopping\n",
      "Count Down: 6\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3945\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3274\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 1.3913\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3147\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3499\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2939\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3132\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3765\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3184\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3284\n",
      "Epoch 10: early stopping\n",
      "Count Down: 5\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3142\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3394\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2752\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3710\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2924\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2569\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3093\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2619\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3308\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3381\n",
      "Epoch 10: early stopping\n",
      "Count Down: 4\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.4111\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3024\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2578\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2252\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3609\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2516\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2049\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2899\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1881\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3689\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3086\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1874\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2221\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.3256\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.1868\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3353\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.3636\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2761\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 1.2446\n",
      "Epoch 19: early stopping\n",
      "Count Down: 3\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2084\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2393\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1971\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2705\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1948\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1658\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1293\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2685\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2273\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2103\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1936\n",
      "Epoch 11: early stopping\n",
      "Count Down: 2\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2485\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1528\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1274\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1846\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2046\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2087\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2881\n",
      "Epoch 7: early stopping\n",
      "Count Down: 1\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2420\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1699\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.0775\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1454\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1332\n",
      "Epoch 6/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 1.1168\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1.2182\n",
      "Epoch 7: early stopping\n",
      "Count Down: 0\n"
     ]
    }
   ],
   "source": [
    "num_companies = 1  # 29 companies in our dataset.\n",
    "days = 5\n",
    "step_rows  = 24 * num_companies * 5  # 24 time periods per day per stock\n",
    "total_rows = len(f['2022-06-01':'2022-12-30'])  # Define total length to predict on\n",
    "train_rows = len(f['2022-06-01':'2022-08-31'])  # Define length of training window\n",
    "\n",
    "\n",
    "scale_X = MinMaxScaler()\n",
    "model_2 = Sequential()\n",
    "model_2.add(Dense(100, activation = 'relu', input_dim = f.iloc[:,1:-1].shape[1]))  # initiating with 100 neurons\n",
    "model_2.add(Dense(100, activation = 'relu', input_dim = f.iloc[:,1:-1].shape[1]))\n",
    "model_2.add(Dropout(0.25))                                                          # adding dropout to avoid overfitting\n",
    "model_2.add(Dense(1))                                                               # output layer\n",
    "\n",
    "opt = Adam(amsgrad = True, lr = 0.001, beta_1 = 0.79, beta_2 = 0.999)             # using Adam optimizer, at a learning rate of 0.001\n",
    "model_2.compile(loss = 'mse', optimizer = opt)                                      # compiling model\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "f_result = pd.DataFrame(columns=['DATETIME', 'ACTUAL', 'PREDICTED', 'DIFFERENCE', 'TRAIN_DURATION'])\n",
    "\n",
    "for i in range(0, total_rows - train_rows, step_rows):\n",
    "    st = time.time()\n",
    "    # 1. Obtain X and y\n",
    "    train  = f.iloc[i:train_rows + i, 1:] \n",
    "    test   = f.iloc[train_rows + i:train_rows + i + step_rows, 1:]  \n",
    "    X_train, y_train = train.iloc[:, 1:], train.iloc[:, 0]\n",
    "    X_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]\n",
    "\n",
    "\n",
    "    \n",
    "    # 2. Scale X\n",
    "    X_train = scale_X.fit_transform(X_train)\n",
    "    X_test = scale_X.transform(X_test)\n",
    "\n",
    "    # 3. Fit and Predict\n",
    "    model_2.fit(X_train, y_train, epochs=200, batch_size=256, callbacks=[es])\n",
    "    y_hat = model_2.predict(X_test, verbose=False)\n",
    "    et = time.time()\n",
    "\n",
    "    # 4. Save data with prediction\n",
    "    fecha = DATETIME[train_rows + i:train_rows + i + step_rows]\n",
    "    datos = {\n",
    "        'DATETIME': fecha.ravel(),\n",
    "        'ACTUAL': y_test.ravel(),\n",
    "        'PREDICTED': y_hat.ravel(),\n",
    "        'DIFFERENCE': abs(y_hat.ravel() - y_test.ravel()),\n",
    "        'TRAIN_DURATION': np.full(y_hat.ravel().shape[0], et - st)\n",
    "    }\n",
    "    data = pd.DataFrame(data=datos)\n",
    "    f_result = pd.concat([f_result, data], ignore_index=True)\n",
    "\n",
    "    print(\"Count Down:\", int((total_rows - train_rows - i) / step_rows))\n",
    "    # print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61a9d522",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 4ms/step - loss: 29095.5723\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 28806.1270\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 28375.4375\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 27652.2832\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 26470.9004\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 24690.0703\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 22143.4277\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 18803.9961\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 14876.7510\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 10639.5195\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 6606.2515\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 3389.3105\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1389.6752\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 540.6057\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 339.2168\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 333.6745\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 308.5519\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 281.4144\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 288.1928\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 295.2778\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 270.7019\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 276.5798\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 268.8553\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 276.5163\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 259.1933\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 249.4069\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 255.0157\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 245.6279\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 236.0066\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 232.5316\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 232.9588\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 236.5872\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 234.3915\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 246.9849\n",
      "Epoch 34: early stopping\n",
      "Count Down: 16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 256.6519\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 244.0480\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 243.0035\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 219.1965\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 231.7645\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 227.3032\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 220.2349\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 223.6556\n",
      "Epoch 8: early stopping\n",
      "Count Down: 15\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 207.3735\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 209.4438\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 200.0071\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 199.3993\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 207.7057\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 200.0401\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 199.6695\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 193.8525\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 205.7370\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 197.4305\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 199.1653\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 188.6573\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 189.6217\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 202.8624\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 186.8769\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 194.1363\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 203.8521\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 193.6655\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 191.9378\n",
      "Epoch 19: early stopping\n",
      "Count Down: 14\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 210.0476\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 181.8975\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 188.4852\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 175.5112\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 179.2227\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 173.6964\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 181.1379\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 187.3228\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 181.6183\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 176.0950\n",
      "Epoch 10: early stopping\n",
      "Count Down: 13\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 218.9575\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 190.0887\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 183.6146\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 180.4066\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 182.2910\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 175.8560\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 173.5595\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 171.8815\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 170.3234\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 173.6333\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 168.6259\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 169.2523\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 172.9243\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 172.0476\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 172.2060\n",
      "Epoch 15: early stopping\n",
      "Count Down: 12\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 189.0173\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 176.6084\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 170.4498\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 176.3315\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 174.7407\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 172.7654\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 165.6086\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 166.1486\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 163.5266\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 167.7627\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 171.8585\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 163.1149\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 173.3176\n",
      "Epoch 14/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 164.7922\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 171.0758\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 165.9378\n",
      "Epoch 16: early stopping\n",
      "Count Down: 11\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 165.3182\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 162.7847\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 163.0697\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.1264\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 160.7456\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 165.9982\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.1736\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 150.7955\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 150.1750\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 164.4098\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 159.9172\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 165.6002\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 156.3326\n",
      "Epoch 13: early stopping\n",
      "Count Down: 10\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.4130\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 162.6675\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 150.3667\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.0988\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 154.2737\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 148.7862\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 139.1085\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.1150\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 155.1236\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 161.2345\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 148.5113\n",
      "Epoch 11: early stopping\n",
      "Count Down: 9\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 145.9328\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 147.0328\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 151.7199\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 136.4057\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 141.8555\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 139.2107\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 140.5535\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 144.3050\n",
      "Epoch 8: early stopping\n",
      "Count Down: 8\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 183.8223\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 159.2908\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 146.7652\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 140.7977\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.7478\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 133.8739\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.8681\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.5150\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 127.2771\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 131.1124\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 133.0606\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 129.4994\n",
      "Epoch 12: early stopping\n",
      "Count Down: 7\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 140.4053\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.9976\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 134.9608\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 126.9844\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.7841\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.6615\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 125.1007\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 136.5678\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.0186\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 125.4415\n",
      "Epoch 10: early stopping\n",
      "Count Down: 6\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 126.4143\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 122.8046\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 125.6153\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 5ms/step - loss: 123.6507\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 122.9412\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 123.3880\n",
      "Epoch 6: early stopping\n",
      "Count Down: 5\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 124.7191\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 119.5663\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 126.4423\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.9165\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 117.2492\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 117.8208\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 121.4054\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 113.1280\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 119.0297\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 118.2525\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 111.3127\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 115.0735\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.9850\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 116.7745\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 124.0639\n",
      "Epoch 15: early stopping\n",
      "Count Down: 4\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 128.7120\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 120.3733\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 116.0716\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 121.2000\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 116.3451\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 117.2392\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 119.8180\n",
      "Epoch 7: early stopping\n",
      "Count Down: 3\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 153.5520\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 138.9517\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 135.2437\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.6875\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.9596\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 132.1867\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 134.0546\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.4661\n",
      "Epoch 8: early stopping\n",
      "Count Down: 2\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 144.1557\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 135.5839\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 140.8683\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 141.9519\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.5278\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 129.3487\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 124.0594\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 126.4202\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 130.5217\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.9453\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.9430\n",
      "Epoch 11: early stopping\n",
      "Count Down: 1\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 158.5822\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 149.9366\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 137.9750\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 150.9944\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 162.3006\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.5292\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 156.5057\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 138.0916\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 144.4993\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 140.4251\n",
      "Epoch 10: early stopping\n",
      "Count Down: 0\n"
     ]
    }
   ],
   "source": [
    "num_companies = 1  # 29 companies in our dataset.\n",
    "days = 5\n",
    "step_rows  = 24 * num_companies * 5  # 24 time periods per day per stock\n",
    "total_rows = len(nvda['2022-06-01':'2022-12-30'])  # Define total length to predict on\n",
    "train_rows = len(nvda['2022-06-01':'2022-08-31'])  # Define length of training window\n",
    "\n",
    "\n",
    "scale_X = MinMaxScaler()\n",
    "model_3 = Sequential()\n",
    "model_3.add(Dense(100, activation = 'relu', input_dim = nvda.iloc[:,1:-1].shape[1]))  # initiating with 100 neurons\n",
    "model_3.add(Dense(100, activation = 'relu', input_dim = nvda.iloc[:,1:-1].shape[1]))\n",
    "model_3.add(Dropout(0.25))                                                          # adding dropout to avoid overfitting\n",
    "model_3.add(Dense(1))                                                               # output layer\n",
    "\n",
    "opt = Adam(amsgrad = True, lr = 0.001, beta_1 = 0.79, beta_2 = 0.999)             # using Adam optimizer, at a learning rate of 0.001\n",
    "model_3.compile(loss = 'mse', optimizer = opt)                                      # compiling model\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "nvda_result = pd.DataFrame(columns=['DATETIME', 'ACTUAL', 'PREDICTED', 'DIFFERENCE', 'TRAIN_DURATION'])\n",
    "\n",
    "for i in range(0, total_rows - train_rows, step_rows):\n",
    "    st = time.time()\n",
    "    # 1. Obtain X and y\n",
    "    train  = nvda.iloc[i:train_rows + i, 1:] \n",
    "    test   = nvda.iloc[train_rows + i:train_rows + i + step_rows, 1:]  \n",
    "    X_train, y_train = train.iloc[:, 1:], train.iloc[:, 0]\n",
    "    X_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]\n",
    "\n",
    "\n",
    "    \n",
    "    # 2. Scale X\n",
    "    X_train = scale_X.fit_transform(X_train)\n",
    "    X_test = scale_X.transform(X_test)\n",
    "\n",
    "    # 3. Fit and Predict\n",
    "    model_3.fit(X_train, y_train, epochs=200, batch_size=256, callbacks=[es])\n",
    "    y_hat = model_3.predict(X_test, verbose=False)\n",
    "    et = time.time()\n",
    "\n",
    "    # 4. Save data with prediction\n",
    "    fecha = DATETIME[train_rows + i:train_rows + i + step_rows]\n",
    "    datos = {\n",
    "        'DATETIME': fecha.ravel(),\n",
    "        'ACTUAL': y_test.ravel(),\n",
    "        'PREDICTED': y_hat.ravel(),\n",
    "        'DIFFERENCE': abs(y_hat.ravel() - y_test.ravel()),\n",
    "        'TRAIN_DURATION': np.full(y_hat.ravel().shape[0], et - st)\n",
    "    }\n",
    "    data = pd.DataFrame(data=datos)\n",
    "    nvda_result = pd.concat([nvda_result, data], ignore_index=True)\n",
    "\n",
    "    print(\"Count Down:\", int((total_rows - train_rows - i) / step_rows))\n",
    "    # print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6505ca58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 69275.6953\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 68947.4766\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 68516.8359\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 67833.7188\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 66673.1250\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 64798.2344\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 61936.2305\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 57892.8555\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 52427.5273\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 45635.4414\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 37844.6289\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 29586.8496\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 21218.4590\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 13861.2607\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 8104.0059\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 4322.0562\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2343.8091\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1534.5660\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1322.4166\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1154.4889\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1135.1025\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1056.3156\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1099.3518\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1055.8268\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 976.9722\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 970.0093\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 967.2753\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 887.9402\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 879.8859\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 868.6275\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 858.3203\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 836.6729\n",
      "Epoch 33/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 811.9795\n",
      "Epoch 34/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 736.1997\n",
      "Epoch 35/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 773.2793\n",
      "Epoch 36/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 697.4199\n",
      "Epoch 37/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 721.4435\n",
      "Epoch 38/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 705.9310\n",
      "Epoch 39/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 678.4757\n",
      "Epoch 40/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 713.3880\n",
      "Epoch 41/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 660.5816\n",
      "Epoch 42/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 692.1137\n",
      "Epoch 43/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 640.3322\n",
      "Epoch 44/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 585.9509\n",
      "Epoch 45/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 640.3533\n",
      "Epoch 46/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 634.4893\n",
      "Epoch 47/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 634.6146\n",
      "Epoch 48/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 639.6494\n",
      "Epoch 48: early stopping\n",
      "Count Down: 16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 762.4326\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 678.8651\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 677.6670\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 720.3091\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 635.8608\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 648.6662\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 645.2065\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 633.4300\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 570.6348\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 597.2520\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 640.1478\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 563.1215\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 650.5756\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 643.7368\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 604.5714\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 594.9729\n",
      "Epoch 16: early stopping\n",
      "Count Down: 15\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 665.8415\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 683.9946\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 647.2479\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 600.8293\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 595.8704\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 554.9879\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 631.5660\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 617.5386\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 636.8236\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 613.2770\n",
      "Epoch 10: early stopping\n",
      "Count Down: 14\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 846.9328\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 688.8376\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 744.4894\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 667.5753\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 670.9067\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 613.5209\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 695.2158\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 683.4409\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 639.9800\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 683.9377\n",
      "Epoch 10: early stopping\n",
      "Count Down: 13\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 682.0963\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 644.1804\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 667.7220\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 665.0648\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 641.0510\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 677.7906\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 649.4101\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 670.0582\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 636.2936\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 626.7386\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 627.3271\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 611.5500\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 673.1546\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 636.2076\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 666.4445\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 641.8842\n",
      "Epoch 16: early stopping\n",
      "Count Down: 12\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 689.2023\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 644.2565\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 664.8934\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 648.2739\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 656.7352\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 648.8992\n",
      "Epoch 6: early stopping\n",
      "Count Down: 11\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 657.8708\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 635.0250\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 638.4140\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 625.1655\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 649.5325\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 631.5421\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 683.0259\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 624.1622\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 641.6782\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 638.4138\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 588.1259\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 622.5122\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 604.9754\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 656.3224\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 614.9083\n",
      "Epoch 15: early stopping\n",
      "Count Down: 10\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 654.3288\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 680.5810\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 662.3851\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 667.6361\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 675.8246\n",
      "Epoch 5: early stopping\n",
      "Count Down: 9\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 728.8276\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 726.1155\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 712.4500\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 710.2176\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 699.7490\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 663.1804\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 700.6470\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 689.9170\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 621.1247\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 684.1660\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 632.7224\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 719.2678\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 665.3505\n",
      "Epoch 13: early stopping\n",
      "Count Down: 8\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 813.6693\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 766.6716\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 726.6231\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 703.2288\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 689.1616\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 681.6143\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 710.5624\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 658.4260\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 624.4582\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 614.3579\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 637.8233\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 653.8577\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 630.5500\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 651.1628\n",
      "Epoch 14: early stopping\n",
      "Count Down: 7\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 744.0972\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 751.7862\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 685.5676\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 653.5272\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 620.2214\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 634.1634\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 656.1066\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 636.6740\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 626.6353\n",
      "Epoch 9: early stopping\n",
      "Count Down: 6\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 708.4116\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 684.7862\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 661.1717\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 647.2176\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 650.5204\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 662.2632\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 635.7161\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 649.6927\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 606.5377\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 617.0421\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 628.3737\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 601.6609\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 643.3561\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 663.8283\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 606.4719\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 616.6975\n",
      "Epoch 16: early stopping\n",
      "Count Down: 5\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 653.2869\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 576.4274\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 588.2094\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 566.7773\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 593.9348\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 606.0916\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 607.6818\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 520.3201\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 583.7145\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 594.6865\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 582.7664\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 545.1343\n",
      "Epoch 12: early stopping\n",
      "Count Down: 4\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 969.8605\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 769.2917\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 723.9756\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 661.2044\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 611.3666\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 591.0883\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 550.1975\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 535.0322\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 514.1691\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 522.5949\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 517.9814\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 503.8064\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 544.7415\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 487.2735\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 505.5602\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 534.8079\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 507.6623\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 502.0355\n",
      "Epoch 18: early stopping\n",
      "Count Down: 3\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 474.9136\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 456.1997\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 500.6629\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 455.2393\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 471.0103\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 455.9205\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 476.6207\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 425.3281\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 439.7555\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 473.9932\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 430.7988\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 467.0807\n",
      "Epoch 12: early stopping\n",
      "Count Down: 2\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 409.8891\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 400.5284\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 408.6932\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 401.4296\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 399.7603\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 423.7902\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 380.7362\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 386.4515\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 401.4309\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 404.6659\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 385.8968\n",
      "Epoch 11: early stopping\n",
      "Count Down: 1\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 460.0584\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 421.5702\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 420.1000\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 431.7022\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 390.0041\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 406.2388\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 381.5969\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 409.6082\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 367.4120\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 383.1514\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 391.1818\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 371.0616\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 365.7607\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 387.8100\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 363.6799\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 354.3180\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 340.9225\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 363.7470\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 356.1167\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 356.8905\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 362.2922\n",
      "Epoch 21: early stopping\n",
      "Count Down: 0\n"
     ]
    }
   ],
   "source": [
    "num_companies = 1  # 29 companies in our dataset.\n",
    "days = 5\n",
    "step_rows  = 24 * num_companies * 5  # 24 time periods per day per stock\n",
    "total_rows = len(tsla['2022-06-01':'2022-12-30'])  # Define total length to predict on\n",
    "train_rows = len(tsla['2022-06-01':'2022-08-31'])  # Define length of training window\n",
    "\n",
    "\n",
    "scale_X = MinMaxScaler()\n",
    "model_4 = Sequential()\n",
    "model_4.add(Dense(100, activation = 'relu', input_dim = tsla.iloc[:,1:-1].shape[1]))  # initiating with 100 neurons\n",
    "model_4.add(Dense(100, activation = 'relu', input_dim = tsla.iloc[:,1:-1].shape[1]))\n",
    "model_4.add(Dropout(0.25))                                                          # adding dropout to avoid overfitting\n",
    "model_4.add(Dense(1))                                                               # output layer\n",
    "\n",
    "opt = Adam(amsgrad = True, lr = 0.001, beta_1 = 0.79, beta_2 = 0.999)             # using Adam optimizer, at a learning rate of 0.001\n",
    "model_4.compile(loss = 'mse', optimizer = opt)                                      # compiling model\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "tsla_result = pd.DataFrame(columns=['DATETIME', 'ACTUAL', 'PREDICTED', 'DIFFERENCE', 'TRAIN_DURATION'])\n",
    "\n",
    "for i in range(0, total_rows - train_rows, step_rows):\n",
    "    st = time.time()\n",
    "    # 1. Obtain X and y\n",
    "    train  = tsla.iloc[i:train_rows + i, 1:] \n",
    "    test   = tsla.iloc[train_rows + i:train_rows + i + step_rows, 1:]  \n",
    "    X_train, y_train = train.iloc[:, 1:], train.iloc[:, 0]\n",
    "    X_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]\n",
    "\n",
    "\n",
    "    \n",
    "    # 2. Scale X\n",
    "    X_train = scale_X.fit_transform(X_train)\n",
    "    X_test = scale_X.transform(X_test)\n",
    "\n",
    "    # 3. Fit and Predict\n",
    "    model_4.fit(X_train, y_train, epochs=200, batch_size=256, callbacks=[es])\n",
    "    y_hat = model_4.predict(X_test, verbose=False)\n",
    "    et = time.time()\n",
    "\n",
    "    # 4. Save data with prediction\n",
    "    fecha = DATETIME[train_rows + i:train_rows + i + step_rows]\n",
    "    datos = {\n",
    "        'DATETIME': fecha.ravel(),\n",
    "        'ACTUAL': y_test.ravel(),\n",
    "        'PREDICTED': y_hat.ravel(),\n",
    "        'DIFFERENCE': abs(y_hat.ravel() - y_test.ravel()),\n",
    "        'TRAIN_DURATION': np.full(y_hat.ravel().shape[0], et - st)\n",
    "    }\n",
    "    data = pd.DataFrame(data=datos)\n",
    "    tsla_result = pd.concat([tsla_result, data], ignore_index=True)\n",
    "\n",
    "    print(\"Count Down:\", int((total_rows - train_rows - i) / step_rows))\n",
    "    # print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b335356f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "6/6 [==============================] - 1s 3ms/step - loss: 16268.7422\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 16043.3037\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 15721.0352\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 15210.5107\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 14415.4697\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 13245.3643\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 11592.6455\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 9508.2725\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 7128.9956\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 4702.0620\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 2569.4114\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 1119.5746\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 425.1187\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 237.3224\n",
      "Epoch 15/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 219.6288\n",
      "Epoch 16/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 203.8672\n",
      "Epoch 17/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 194.0421\n",
      "Epoch 18/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 198.4203\n",
      "Epoch 19/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 169.9208\n",
      "Epoch 20/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 191.3250\n",
      "Epoch 21/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 190.3370\n",
      "Epoch 22/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 166.5331\n",
      "Epoch 23/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 159.2664\n",
      "Epoch 24/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 167.5629\n",
      "Epoch 25/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 159.3736\n",
      "Epoch 26/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 151.5114\n",
      "Epoch 27/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 145.2331\n",
      "Epoch 28/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 140.3654\n",
      "Epoch 29/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 146.6242\n",
      "Epoch 30/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 149.5571\n",
      "Epoch 31/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 144.2260\n",
      "Epoch 32/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 141.6631\n",
      "Epoch 32: early stopping\n",
      "Count Down: 16\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 161.1174\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 158.7677\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 135.5508\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.1506\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 136.4433\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 137.2546\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.2611\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 125.9716\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 119.8382\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 128.1099\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 129.2856\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 131.9350\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 125.0302\n",
      "Epoch 13: early stopping\n",
      "Count Down: 15\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 124.1907\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.6238\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.6552\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.3170\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 126.7857\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 116.2149\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.1914\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 118.3042\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.0448\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 117.3386\n",
      "Epoch 10: early stopping\n",
      "Count Down: 14\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 131.6922\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.4733\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 124.4364\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.5883\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 112.9936\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 124.0142\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.3507\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 121.0340\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 121.5398\n",
      "Epoch 9: early stopping\n",
      "Count Down: 13\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 134.1237\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 121.4229\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 121.4461\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 111.8240\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.5060\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 115.6554\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 118.6691\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 110.5137\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 119.5019\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 115.2293\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 116.0446\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 122.9289\n",
      "Epoch 12: early stopping\n",
      "Count Down: 12\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 130.4317\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 117.0894\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 119.9429\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 120.9232\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 117.5704\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 116.4664\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 111.8080\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 110.9757\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 113.9542\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 114.5459\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 119.0028\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 119.6798\n",
      "Epoch 12: early stopping\n",
      "Count Down: 11\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 123.1017\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.1621\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 117.0892\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 118.9106\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 113.7376\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 120.1301\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 116.6745\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 111.5908\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 118.5969\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 111.3862\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 117.4232\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 114.0868\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 114.1089\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 119.0948\n",
      "Epoch 14: early stopping\n",
      "Count Down: 10\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 121.0515\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 117.7568\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 117.5658\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 114.8523\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 117.3351\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 121.8392\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 118.7747\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 114.9269\n",
      "Epoch 8: early stopping\n",
      "Count Down: 9\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 116.9071\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 118.8903\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.9301\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 112.5180\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.7932\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 118.2740\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 109.7108\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.4568\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 110.1571\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 113.3362\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 114.2589\n",
      "Epoch 11: early stopping\n",
      "Count Down: 8\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 125.4083\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 121.2673\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.0198\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 119.5702\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 114.7124\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 115.1559\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 114.7987\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.2149\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 120.2680\n",
      "Epoch 9: early stopping\n",
      "Count Down: 7\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 122.3450\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 123.4927\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 117.7212\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 115.3664\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 117.1426\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 113.4236\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 115.9224\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 114.5878\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 114.9009\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 118.3450\n",
      "Epoch 10: early stopping\n",
      "Count Down: 6\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 122.0035\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 4ms/step - loss: 124.7343\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 122.2991\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.2286\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 122.4225\n",
      "Epoch 5: early stopping\n",
      "Count Down: 5\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 135.8601\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.2213\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.6805\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.6862\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.3041\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.0858\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.7566\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 122.0000\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.0730\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 115.1722\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.8844\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.8832\n",
      "Epoch 13/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.5000\n",
      "Epoch 14/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 126.2087\n",
      "Epoch 14: early stopping\n",
      "Count Down: 4\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 139.7630\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 136.6770\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.3937\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 138.3147\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 126.9535\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 129.7675\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.1816\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 129.3329\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.1528\n",
      "Epoch 9: early stopping\n",
      "Count Down: 3\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.9697\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.2463\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.2407\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.3664\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.1002\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.3143\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.6949\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 123.1766\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.7839\n",
      "Epoch 10/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 126.3921\n",
      "Epoch 11/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 129.8435\n",
      "Epoch 12/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.0678\n",
      "Epoch 12: early stopping\n",
      "Count Down: 2\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 129.7354\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.4081\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 129.8102\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.7367\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 131.7916\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 132.9851\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 133.9336\n",
      "Epoch 8/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 130.7633\n",
      "Epoch 8: early stopping\n",
      "Count Down: 1\n",
      "Epoch 1/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 142.9898\n",
      "Epoch 2/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 145.6607\n",
      "Epoch 3/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 141.0558\n",
      "Epoch 4/200\n",
      "6/6 [==============================] - 0s 2ms/step - loss: 142.8026\n",
      "Epoch 5/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 127.4360\n",
      "Epoch 6/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 135.0972\n",
      "Epoch 7/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 135.4767\n",
      "Epoch 8/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 3ms/step - loss: 133.5124\n",
      "Epoch 9/200\n",
      "6/6 [==============================] - 0s 3ms/step - loss: 128.9157\n",
      "Epoch 9: early stopping\n",
      "Count Down: 0\n"
     ]
    }
   ],
   "source": [
    "num_companies = 1  # 29 companies in our dataset.\n",
    "days = 5\n",
    "step_rows  = 24 * num_companies * 5  # 24 time periods per day per stock\n",
    "total_rows = len(wmt['2022-06-01':'2022-12-30'])  # Define total length to predict on\n",
    "train_rows = len(wmt['2022-06-01':'2022-08-31'])  # Define length of training window\n",
    "\n",
    "\n",
    "scale_X = MinMaxScaler()\n",
    "model_5 = Sequential()\n",
    "model_5.add(Dense(100, activation = 'relu', input_dim = wmt.iloc[:,1:-1].shape[1]))  # initiating with 100 neurons\n",
    "model_5.add(Dense(100, activation = 'relu', input_dim = wmt.iloc[:,1:-1].shape[1]))\n",
    "model_5.add(Dropout(0.25))                                                          # adding dropout to avoid overfitting\n",
    "model_5.add(Dense(1))                                                               # output layer\n",
    "\n",
    "opt = Adam(amsgrad = True, lr = 0.001, beta_1 = 0.79, beta_2 = 0.999)             # using Adam optimizer, at a learning rate of 0.001\n",
    "model_5.compile(loss = 'mse', optimizer = opt)                                      # compiling model\n",
    "es = EarlyStopping(monitor='loss', mode='min', verbose=1, patience=4)\n",
    "\n",
    "wmt_result = pd.DataFrame(columns=['DATETIME', 'ACTUAL', 'PREDICTED', 'DIFFERENCE', 'TRAIN_DURATION'])\n",
    "\n",
    "for i in range(0, total_rows - train_rows, step_rows):\n",
    "    st = time.time()\n",
    "    # 1. Obtain X and y\n",
    "    train  = wmt.iloc[i:train_rows + i, 1:] \n",
    "    test   = wmt.iloc[train_rows + i:train_rows + i + step_rows, 1:]  \n",
    "    X_train, y_train = train.iloc[:, 1:], train.iloc[:, 0]\n",
    "    X_test, y_test = test.iloc[:, 1:], test.iloc[:, 0]\n",
    "\n",
    "\n",
    "    \n",
    "    # 2. Scale X\n",
    "    X_train = scale_X.fit_transform(X_train)\n",
    "    X_test = scale_X.transform(X_test)\n",
    "\n",
    "    # 3. Fit and Predict\n",
    "    model_5.fit(X_train, y_train, epochs=200, batch_size=256, callbacks=[es])\n",
    "    y_hat = model_5.predict(X_test, verbose=False)\n",
    "    et = time.time()\n",
    "\n",
    "    # 4. Save data with prediction\n",
    "    fecha = DATETIME[train_rows + i:train_rows + i + step_rows]\n",
    "    datos = {\n",
    "        'DATETIME': fecha.ravel(),\n",
    "        'ACTUAL': y_test.ravel(),\n",
    "        'PREDICTED': y_hat.ravel(),\n",
    "        'DIFFERENCE': abs(y_hat.ravel() - y_test.ravel()),\n",
    "        'TRAIN_DURATION': np.full(y_hat.ravel().shape[0], et - st)\n",
    "    }\n",
    "    data = pd.DataFrame(data=datos)\n",
    "    wmt_result = pd.concat([wmt_result, data], ignore_index=True)\n",
    "\n",
    "    print(\"Count Down:\", int((total_rows - train_rows - i) / step_rows))\n",
    "    # print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1a16ba88",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df = pd.DataFrame(columns = ['stock_ID', \"RMSE\", \"MAPE\", \"MPE\", \"MTT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ded34edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_positive_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    error = np.mean(np.maximum((y_pred - y_true),0))\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21ab8fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_ID</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>9.64181</td>\n",
       "      <td>4.895383</td>\n",
       "      <td>4.261478</td>\n",
       "      <td>0.393937</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_ID     RMSE      MAPE       MPE       MTT\n",
       "0     AAPL  9.64181  4.895383  4.261478  0.393937"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows = []\n",
    "stock_result = aapl_result\n",
    "# Calculate RMSE \n",
    "rmse = np.sqrt(mean_squared_error(stock_result['ACTUAL'], stock_result['PREDICTED']))\n",
    "# Calculate MAPE % \n",
    "mape = mean_absolute_percentage_error(stock_result['ACTUAL'], stock_result['PREDICTED']) * 100\n",
    "# Calculate MPE % \n",
    "mpe = mean_positive_error(stock_result['ACTUAL'],stock_result['PREDICTED'])\n",
    "# Calculate MTT in seconds \n",
    "mtt = np.mean(stock_result['TRAIN_DURATION'])\n",
    "new_row = pd.Series(['AAPL',rmse, mape, mpe, mtt], index=metrics_df.columns)\n",
    "new_rows.append(new_row)\n",
    "metrics_df = pd.DataFrame(new_rows)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e4026250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_ID</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>F</td>\n",
       "      <td>0.968666</td>\n",
       "      <td>5.483406</td>\n",
       "      <td>0.429655</td>\n",
       "      <td>0.423006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_ID      RMSE      MAPE       MPE       MTT\n",
       "0        F  0.968666  5.483406  0.429655  0.423006"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows = []\n",
    "stock_result = f_result\n",
    "# Calculate RMSE \n",
    "rmse = np.sqrt(mean_squared_error(stock_result['ACTUAL'], stock_result['PREDICTED']))\n",
    "# Calculate MAPE % \n",
    "mape = mean_absolute_percentage_error(stock_result['ACTUAL'], stock_result['PREDICTED']) * 100\n",
    "# Calculate MPE % \n",
    "mpe = mean_positive_error(stock_result['ACTUAL'],stock_result['PREDICTED'])\n",
    "# Calculate MTT in seconds \n",
    "mtt = np.mean(stock_result['TRAIN_DURATION'])\n",
    "new_row = pd.Series(['F',rmse, mape, mpe, mtt], index=metrics_df.columns)\n",
    "new_rows.append(new_row)\n",
    "metrics_df = pd.DataFrame(new_rows)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dcf2a4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_ID</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>13.384757</td>\n",
       "      <td>7.810694</td>\n",
       "      <td>6.213166</td>\n",
       "      <td>0.50203</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_ID       RMSE      MAPE       MPE      MTT\n",
       "0     NVDA  13.384757  7.810694  6.213166  0.50203"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows = []\n",
    "stock_result = nvda_result\n",
    "# Calculate RMSE \n",
    "rmse = np.sqrt(mean_squared_error(stock_result['ACTUAL'], stock_result['PREDICTED']))\n",
    "# Calculate MAPE % \n",
    "mape = mean_absolute_percentage_error(stock_result['ACTUAL'], stock_result['PREDICTED']) * 100\n",
    "# Calculate MPE % \n",
    "mpe = mean_positive_error(stock_result['ACTUAL'],stock_result['PREDICTED'])\n",
    "# Calculate MTT in seconds \n",
    "mtt = np.mean(stock_result['TRAIN_DURATION'])\n",
    "new_row = pd.Series(['NVDA',rmse, mape, mpe, mtt], index=metrics_df.columns)\n",
    "new_rows.append(new_row)\n",
    "metrics_df = pd.DataFrame(new_rows)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "edabaa94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_ID</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TSLA</td>\n",
       "      <td>35.52258</td>\n",
       "      <td>14.661574</td>\n",
       "      <td>21.319619</td>\n",
       "      <td>0.460251</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_ID      RMSE       MAPE        MPE       MTT\n",
       "0     TSLA  35.52258  14.661574  21.319619  0.460251"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows = []\n",
    "stock_result = tsla_result\n",
    "# Calculate RMSE \n",
    "rmse = np.sqrt(mean_squared_error(stock_result['ACTUAL'], stock_result['PREDICTED']))\n",
    "# Calculate MAPE % \n",
    "mape = mean_absolute_percentage_error(stock_result['ACTUAL'], stock_result['PREDICTED']) * 100\n",
    "# Calculate MPE % \n",
    "mpe = mean_positive_error(stock_result['ACTUAL'],stock_result['PREDICTED'])\n",
    "# Calculate MTT in seconds \n",
    "mtt = np.mean(stock_result['TRAIN_DURATION'])\n",
    "new_row = pd.Series(['TSLA',rmse, mape, mpe, mtt], index=metrics_df.columns)\n",
    "new_rows.append(new_row)\n",
    "metrics_df = pd.DataFrame(new_rows)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9a5bc657",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stock_ID</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAPE</th>\n",
       "      <th>MPE</th>\n",
       "      <th>MTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WMT</td>\n",
       "      <td>9.600499</td>\n",
       "      <td>5.318621</td>\n",
       "      <td>1.60342</td>\n",
       "      <td>0.407181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stock_ID      RMSE      MAPE      MPE       MTT\n",
       "0      WMT  9.600499  5.318621  1.60342  0.407181"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_rows = []\n",
    "stock_result = wmt_result\n",
    "# Calculate RMSE \n",
    "rmse = np.sqrt(mean_squared_error(stock_result['ACTUAL'], stock_result['PREDICTED']))\n",
    "# Calculate MAPE % \n",
    "mape = mean_absolute_percentage_error(stock_result['ACTUAL'], stock_result['PREDICTED']) * 100\n",
    "# Calculate MPE % \n",
    "mpe = mean_positive_error(stock_result['ACTUAL'],stock_result['PREDICTED'])\n",
    "# Calculate MTT in seconds \n",
    "mtt = np.mean(stock_result['TRAIN_DURATION'])\n",
    "new_row = pd.Series(['WMT',rmse, mape, mpe, mtt], index=metrics_df.columns)\n",
    "new_rows.append(new_row)\n",
    "metrics_df = pd.DataFrame(new_rows)\n",
    "metrics_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
